services:
  cuda-qwen:
    image: vllm/vllm-openai:v0.6.6.post1
    command:
      - --device
      - cuda
      - --model
      - Qwen/Qwen2.5-1.5B-Instruct
    volumes:
      - .cache/huggingface:/root/.cache/huggingface
    ports:
      - 8000:8000
    ipc: host
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
